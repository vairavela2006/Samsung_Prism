{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yT2PcbVeD0i",
        "outputId": "4709bde2-9c93-4bb3-d1ec-89ad400fbeb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.12.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers peft datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "yHPsAufzeuGE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpellCorrectionDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_len=128):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.data = json.load(f)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            item[\"sentence\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze()\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
        "\n",
        "        mask_index = (input_ids == self.tokenizer.mask_token_id).nonzero(as_tuple=True)[0].item()\n",
        "\n",
        "        candidate_ids = self.tokenizer.convert_tokens_to_ids(item[\"candidates\"])\n",
        "        label_index = item[\"candidates\"].index(item[\"label\"])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"mask_index\": mask_index,\n",
        "            \"candidate_ids\": torch.tensor(candidate_ids),\n",
        "            \"label_index\": torch.tensor(label_index)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "BHL_tXBOewBg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\")\n",
        "base_model = AutoModelForMaskedLM.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qPSUpEYeyiE",
        "outputId": "7648e7ee-1883-4979-ccb6-5fc60435a608"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"TOKEN_CLS\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Zo15JKez1Z",
        "outputId": "a43de6d5-4f92-434e-b9de-1fe8f08bb9c9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForTokenClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): BertForMaskedLM(\n",
              "      (bert): BertModel(\n",
              "        (embeddings): BertEmbeddings(\n",
              "          (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
              "          (position_embeddings): Embedding(512, 384)\n",
              "          (token_type_embeddings): Embedding(2, 384)\n",
              "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): BertEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0-11): 12 x BertLayer(\n",
              "              (attention): BertAttention(\n",
              "                (self): BertSdpaSelfAttention(\n",
              "                  (query): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=384, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=384, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): BertSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): BertIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): BertOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (cls): BertOnlyMLMHead(\n",
              "        (predictions): BertLMPredictionHead(\n",
              "          (transform): BertPredictionHeadTransform(\n",
              "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (transform_act_fn): GELUActivation()\n",
              "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (decoder): Linear(in_features=384, out_features=30522, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SpellCorrectionDataset(\"dataset.json\", tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "HU2rwQm8e1i6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
        "\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"]\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        mask_index = batch[\"mask_index\"].item()\n",
        "        candidate_ids = batch[\"candidate_ids\"].squeeze()\n",
        "        label_index = batch[\"label_index\"].item()\n",
        "\n",
        "        mask_logits = logits[0, mask_index]            # [vocab_size]\n",
        "        restricted_logits = mask_logits[candidate_ids] # [num_candidates]\n",
        "\n",
        "        loss = F.cross_entropy(\n",
        "            restricted_logits.unsqueeze(0),\n",
        "            torch.tensor([label_index])\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss / len(dataloader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQVuKB-Xe3AF",
        "outputId": "015a801a-5d66-4f44-bdf6-eba4129530e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 0.7122\n",
            "Epoch 2 | Loss: 0.7287\n",
            "Epoch 3 | Loss: 0.5696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence, candidates):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    mask_index = (inputs[\"input_ids\"][0] == tokenizer.mask_token_id).nonzero(as_tuple=True)[0].item()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    candidate_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
        "    restricted_logits = logits[0, mask_index, candidate_ids]\n",
        "\n",
        "    return candidates[torch.argmax(restricted_logits).item()]\n"
      ],
      "metadata": {
        "id": "cJEtOPl9e4Xa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I went to the [MASK] to buy groceries.\"\n",
        "candidates = [\"market\", \"marcet\", \"markit\"]\n",
        "\n",
        "print(\"Predicted word:\", predict(sentence, candidates))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXWVtBtMe5qY",
        "outputId": "5cc95134-4d54-4650-b77c-2bfad0480101"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted word: market\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X15ml4kglBF",
        "outputId": "cb399ee8-ca24-4317-cb7d-2ffc6f730655"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForTokenClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): BertForMaskedLM(\n",
              "      (bert): BertModel(\n",
              "        (embeddings): BertEmbeddings(\n",
              "          (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
              "          (position_embeddings): Embedding(512, 384)\n",
              "          (token_type_embeddings): Embedding(2, 384)\n",
              "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): BertEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0-11): 12 x BertLayer(\n",
              "              (attention): BertAttention(\n",
              "                (self): BertSdpaSelfAttention(\n",
              "                  (query): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=384, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=384, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): BertSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): BertIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): BertOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (cls): BertOnlyMLMHead(\n",
              "        (predictions): BertLMPredictionHead(\n",
              "          (transform): BertPredictionHeadTransform(\n",
              "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (transform_act_fn): GELUActivation()\n",
              "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (decoder): Linear(in_features=384, out_features=30522, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_spell_correction(sentence, candidates):\n",
        "    \"\"\"\n",
        "    sentence  : string containing [MASK]\n",
        "    candidates: list of candidate words\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    # Find [MASK] index\n",
        "    mask_index = (inputs[\"input_ids\"][0] == tokenizer.mask_token_id).nonzero(as_tuple=True)[0].item()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Convert candidates to token IDs\n",
        "    candidate_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
        "\n",
        "    # Get logits only for [MASK] token\n",
        "    mask_logits = logits[0, mask_index]              # [vocab_size]\n",
        "    restricted_logits = mask_logits[candidate_ids]  # [num_candidates]\n",
        "\n",
        "    # Pick best candidate\n",
        "    predicted_index = torch.argmax(restricted_logits).item()\n",
        "    predicted_word = candidates[predicted_index]\n",
        "\n",
        "    return predicted_word\n"
      ],
      "metadata": {
        "id": "m5OV1hrQgm-W"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests_en = [\n",
        "    (\"She loves to drink [MASK] in the morning.\", [\"coffee\", \"cofee\", \"coffi\"]),\n",
        "    (\"Please close the [MASK] before leaving.\", [\"door\", \"doar\", \"dor\"]),\n",
        "    (\"He is going to the [MASK] for higher studies.\", [\"college\", \"collage\", \"colage\"]),\n",
        "    (\"I forgot my [MASK] at home.\", [\"wallet\", \"walet\", \"vallet\"]),\n",
        "]\n",
        "\n",
        "for sent, cands in tests_en:\n",
        "    print(\"Sentence :\", sent)\n",
        "    print(\"Prediction:\", test_spell_correction(sent, cands))\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ludq5XgIgp4w",
        "outputId": "e92fe9bd-234b-4620-c5e4-6743bfd1f055"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence : She loves to drink [MASK] in the morning.\n",
            "Prediction: coffee\n",
            "--------------------------------------------------\n",
            "Sentence : Please close the [MASK] before leaving.\n",
            "Prediction: door\n",
            "--------------------------------------------------\n",
            "Sentence : He is going to the [MASK] for higher studies.\n",
            "Prediction: college\n",
            "--------------------------------------------------\n",
            "Sentence : I forgot my [MASK] at home.\n",
            "Prediction: wallet\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tests_ko = [\n",
        "    (\"나는 매일 아침 [MASK]를 마신다.\", [\"커피\", \"코피\", \"커피이\"]),\n",
        "    (\"그는 학교에 [MASK] 갔다.\", [\"갔다\", \"같다\", \"갓다\"]),\n",
        "    (\"오늘 날씨가 정말 [MASK].\", [\"좋다\", \"조타\", \"좃다\"]),\n",
        "]\n",
        "\n",
        "for sent, cands in tests_ko:\n",
        "    print(\"Sentence :\", sent)\n",
        "    print(\"Prediction:\", test_spell_correction(sent, cands))\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKOHGi61grKG",
        "outputId": "ad367611-148c-4b8e-dcf5-b9417dd06edc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence : 나는 매일 아침 [MASK]를 마신다.\n",
            "Prediction: 커피\n",
            "--------------------------------------------------\n",
            "Sentence : 그는 학교에 [MASK] 갔다.\n",
            "Prediction: 갔다\n",
            "--------------------------------------------------\n",
            "Sentence : 오늘 날씨가 정말 [MASK].\n",
            "Prediction: 좋다\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}